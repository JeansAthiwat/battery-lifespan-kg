{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-experimental neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b3c0\n",
      "(505,)\n",
      "-0.0003375474769290131\n",
      "b3c1\n",
      "(532,)\n",
      "-0.00031199782414543896\n",
      "b3c3\n",
      "(558,)\n",
      "-0.00029250338513364075\n",
      "b3c4\n",
      "(525,)\n",
      "-0.00032999958310808453\n",
      "b3c5\n",
      "(415,)\n",
      "-0.00036687606788543336\n",
      "b3c6\n",
      "(334,)\n",
      "-0.00034274847921497096\n",
      "b3c7\n",
      "(919,)\n",
      "-0.00017601673180182688\n",
      "b3c8\n",
      "(415,)\n",
      "-0.0004105239029390266\n",
      "b3c9\n",
      "(520,)\n",
      "-0.00034236483849011935\n",
      "b3c10\n",
      "(540,)\n",
      "-0.00030462763927601\n",
      "b3c11\n",
      "(409,)\n",
      "-0.00041054688339419934\n",
      "b3c12\n",
      "(467,)\n",
      "-0.0003878696317080512\n",
      "b3c13\n",
      "(409,)\n",
      "-0.0004085456829490755\n",
      "b3c14\n",
      "(430,)\n",
      "-0.0004199655943138655\n",
      "b3c15\n",
      "(439,)\n",
      "-0.00038672131666561466\n",
      "b3c16\n",
      "(820,)\n",
      "-0.00018805926892815567\n",
      "b3c17\n",
      "(658,)\n",
      "-0.0002447868552976104\n",
      "b3c18\n",
      "(574,)\n",
      "-0.00028483761727602226\n",
      "b3c19\n",
      "(578,)\n",
      "-0.0002882764207450576\n",
      "b3c20\n",
      "(407,)\n",
      "-0.0004205898512200583\n",
      "b3c21\n",
      "(387,)\n",
      "-0.00034148609915445017\n",
      "b3c22\n",
      "(502,)\n",
      "-0.0003200144881746209\n",
      "b3c24\n",
      "(413,)\n",
      "-0.00037219247286891246\n",
      "b3c25\n",
      "(495,)\n",
      "-0.000332798861493968\n",
      "b3c26\n",
      "(515,)\n",
      "-0.0003389745082670045\n",
      "b3c27\n",
      "(426,)\n",
      "-0.00038835532228711627\n",
      "b3c28\n",
      "(271,)\n",
      "-0.0004227268079989951\n",
      "b3c29\n",
      "(430,)\n",
      "-0.0003951689531636793\n",
      "b3c30\n",
      "(468,)\n",
      "-0.0003756035087455032\n",
      "b3c31\n",
      "(366,)\n",
      "-0.00048083799784300757\n",
      "b3c33\n",
      "(643,)\n",
      "-0.00024297838077574828\n",
      "b3c34\n",
      "(580,)\n",
      "-0.00027133555247865873\n",
      "b3c35\n",
      "(547,)\n",
      "-0.0002946458089504207\n",
      "b3c36\n",
      "(462,)\n",
      "-0.000341531905260953\n",
      "b3c40\n",
      "(399,)\n",
      "-0.0004083898133203798\n",
      "b3c41\n",
      "(394,)\n",
      "-0.00040689337677156867\n",
      "b3c42\n",
      "(822,)\n",
      "-0.00019574752689278038\n",
      "b3c43\n",
      "(524,)\n",
      "-0.00033452458509052074\n",
      "b3c44\n",
      "(471,)\n",
      "-0.0003806155198698591\n",
      "b3c45\n",
      "(901,)\n",
      "-0.00017983621021486679\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "input_file = \"/home/jeans/nvaitc/battery_timeseries/resources/raw/test_bat_data.pkl\"\n",
    "\n",
    "with open(input_file, \"rb\") as file:\n",
    "    test_dict = pickle.load(file)\n",
    "    \n",
    "for bat in test_dict:\n",
    "    print(bat)\n",
    "    trimmed_arr = np.trim_zeros(test_dict[bat]['q_d_n'], 'b')\n",
    "    test_dict[bat]['trimmed_q_d_n'] = list(trimmed_arr)\n",
    "    test_dict[bat]['gradient_q_d_n'] = list(np.gradient(trimmed_arr))\n",
    "    trimmed_arr = trimmed_arr[len(trimmed_arr)//2:]\n",
    "    print(np.gradient(trimmed_arr).shape)\n",
    "    print(np.mean(np.gradient(trimmed_arr)))\n",
    "    \n",
    "    test_dict[bat]['mean_backhalf_grad'] = np.mean(np.gradient(trimmed_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0003375474769290131 1010\n"
     ]
    }
   ],
   "source": [
    "sample_datapoint = test_dict[list(test_dict.keys())[0]]\n",
    "\n",
    "mean_bh_grad = sample_datapoint['mean_backhalf_grad']\n",
    "cycle = sample_datapoint['cycle']\n",
    "\n",
    "print(mean_bh_grad, cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Battery {batteryID: STRING, mean_backhalf_grad: FLOAT, degradation_cycle: INTEGER}\n",
      "Cycle {batteryID: STRING, cycle_number: INTEGER, discharge_capacity: FLOAT, gradient: FLOAT}\n",
      "Relationship properties:\n",
      "NEXT_CYCLE {gradient: FLOAT}\n",
      "The relationships:\n",
      "(:Battery)-[:HAS_CYCLE]->(:Cycle)\n",
      "(:Cycle)-[:NEXT_CYCLE]->(:Cycle)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"NEO4J_URI\"] = \"neo4j+s://3b31837b.databases.neo4j.io\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"D4W3Zfi44nAJfStBuxSE2DpKhlk_nMP6ybEjvOX5qxw\"\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "graph = Neo4jGraph(refresh_schema=False)\n",
    "\n",
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batteryID': 'b1c24', 'mean_backhalf_grad': -0.0003455189918488088, 'degradation_cycle': 1018}\n",
      "mean_bh_grad_diff 7.971514919795722e-06\n",
      "cycle_diff 8\n",
      "{'batteryID': 'b1c40', 'mean_backhalf_grad': -0.0003809121824939799, 'degradation_cycle': 965}\n",
      "mean_bh_grad_diff 4.3364705564966804e-05\n",
      "cycle_diff 45\n"
     ]
    }
   ],
   "source": [
    "mean_bh_grad_range = 0.1\n",
    "cycle_range = 50\n",
    "#query db for similar node (:Battery) with similar mean_backhalf_grad and cycle\n",
    "# aslo return new attributes showing how close the match is \n",
    "query = f\"\"\"\n",
    "MATCH (b:Battery)\n",
    "WHERE abs(b.mean_backhalf_grad - {mean_bh_grad}) < {mean_bh_grad_range}\n",
    "AND abs(b.degradation_cycle - {cycle}) < {cycle_range}\n",
    "RETURN b\n",
    "\"\"\"\n",
    "results = graph.query(query)    \n",
    "for result in results:\n",
    "    print(result['b'])\n",
    "    print(\"mean_bh_grad_diff\", abs(result['b']['mean_backhalf_grad'] - mean_bh_grad))\n",
    "    print(\"cycle_diff\", abs(result['b']['degradation_cycle'] - cycle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "# Set up NVIDIA ChatNVIDIA LLM\n",
    "llm = ChatNVIDIA(\n",
    "    model=\"mistralai/mixtral-8x22b-instruct-v0.1\",\n",
    "    api_key=os.environ[\"NVIDIA_API_KEY\"],\n",
    "    temperature=0.5,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "# Query the graph database\n",
    "query = \"\"\"\n",
    "MATCH (b:Battery)-[:HAS_CYCLE]->(c:Cycle)\n",
    "RETURN b.batteryID AS batteryID, c.cycle_number AS cycle, c.discharge_capacity AS capacity\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "result = graph.run(query)\n",
    "\n",
    "# Format results for the LLM\n",
    "data = [{\"batteryID\": record[\"batteryID\"], \"cycle\": record[\"cycle\"], \"capacity\": record[\"capacity\"]} for record in result]\n",
    "\n",
    "# Pass to LLM for further analysis\n",
    "prompt = f\"Analyze the following battery data and provide insights:\\n{data}\"\n",
    "for chunk in llm.stream([{\"role\": \"user\", \"content\": prompt}]):\n",
    "    print(chunk.content, end=\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeserie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
